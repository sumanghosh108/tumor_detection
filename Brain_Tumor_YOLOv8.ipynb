{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10938631,"sourceType":"datasetVersion","datasetId":6802518}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary libraries\n!pip install ultralytics\n!pip install plotly\n!pip install opencv-python-headless\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:42:48.250399Z","iopub.execute_input":"2025-05-01T07:42:48.250777Z","iopub.status.idle":"2025-05-01T07:43:03.766435Z","shell.execute_reply.started":"2025-05-01T07:42:48.250742Z","shell.execute_reply":"2025-05-01T07:43:03.765503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to data directories\ntrain_path = \"/kaggle/input/brain-tumor-mri-yolov8/ready_dataset/Train\"\nval_path = \"/kaggle/input/brain-tumor-mri-yolov8/ready_dataset/Val\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:43:03.767790Z","iopub.execute_input":"2025-05-01T07:43:03.768365Z","iopub.status.idle":"2025-05-01T07:43:03.771996Z","shell.execute_reply.started":"2025-05-01T07:43:03.768324Z","shell.execute_reply":"2025-05-01T07:43:03.771129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classes\nclasses = [\"no\", \"yes\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:43:03.773991Z","iopub.execute_input":"2025-05-01T07:43:03.774253Z","iopub.status.idle":"2025-05-01T07:43:03.789737Z","shell.execute_reply.started":"2025-05-01T07:43:03.774233Z","shell.execute_reply":"2025-05-01T07:43:03.789141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load images and labels\ndef load_data(data_path):\n    images = []\n    labels = []\n    for class_label in classes:\n        class_path = os.path.join(data_path, class_label, 'images')\n        label_path = os.path.join(data_path, class_label, 'labels')\n        for img_file in os.listdir(class_path):\n            img = cv2.imread(os.path.join(class_path, img_file))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            label_file = img_file.replace('.png', '.txt')\n            label_file_path = os.path.join(label_path, label_file)\n            if os.path.exists(label_file_path):\n                with open(label_file_path, 'r') as file:\n                    label_data = file.readline().strip().split()\n                    if len(label_data) > 0:\n                        images.append(img)\n                        labels.append(label_data)\n                    else:\n                        print(f\"Label file {label_file_path} is empty, skipping this image.\")\n            else:\n                print(f\"Label file {label_file_path} not found, skipping this image.\")\n    return images, labels\n\n# Load training and validation data\ntrain_images, train_labels = load_data(train_path)\nval_images, val_labels = load_data(val_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:43:03.791116Z","iopub.execute_input":"2025-05-01T07:43:03.791412Z","iopub.status.idle":"2025-05-01T07:45:51.517532Z","shell.execute_reply.started":"2025-05-01T07:43:03.791391Z","shell.execute_reply":"2025-05-01T07:45:51.516810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EDA - Visualize class distribution\ntrain_counts = [len(os.listdir(os.path.join(train_path, cls, 'images'))) for cls in classes]\nval_counts = [len(os.listdir(os.path.join(val_path, cls, 'images'))) for cls in classes]\neda_df = pd.DataFrame({'Class': classes, 'Train': train_counts, 'Validation': val_counts})\n\nfig = go.Figure(data=[\n    go.Bar(name='Train', x=eda_df['Class'], y=eda_df['Train']),\n    go.Bar(name='Validation', x=eda_df['Class'], y=eda_df['Validation'])\n])\nfig.update_layout(barmode='group', title='Class Distribution in Training and Validation Sets')\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:27:06.205787Z","iopub.execute_input":"2025-05-01T16:27:06.206127Z","iopub.status.idle":"2025-05-01T16:27:06.246546Z","shell.execute_reply.started":"2025-05-01T16:27:06.206100Z","shell.execute_reply":"2025-05-01T16:27:06.245571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create YOLOv8 Dataset Configuration File\ndataset_yaml = {\n    'path': '/kaggle/input/brain-tumor-mri-yolov8/ready_dataset',\n    'train': 'Train',\n    'val': 'Val',\n    'names': classes\n}\n\nwith open('/kaggle/working/dataset.yaml', 'w') as file:\n    yaml.dump(dataset_yaml, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:45:51.886924Z","iopub.execute_input":"2025-05-01T07:45:51.887228Z","iopub.status.idle":"2025-05-01T07:45:51.892234Z","shell.execute_reply.started":"2025-05-01T07:45:51.887197Z","shell.execute_reply":"2025-05-01T07:45:51.891658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# YOLOv8 Model Training\nyolo_model = YOLO(\"yolov8s.pt\")  # Load a pre-trained YOLOv8 model\ntrain_results = yolo_model.train(data='/kaggle/working/dataset.yaml', epochs=100, imgsz=640)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T07:45:51.893092Z","iopub.execute_input":"2025-05-01T07:45:51.893344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the YOLOv8 model\nyolo_model.save('/kaggle/working/yolov8_smodel.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:18:05.225239Z","iopub.execute_input":"2025-05-01T16:18:05.225589Z","iopub.status.idle":"2025-05-01T16:18:05.320684Z","shell.execute_reply.started":"2025-05-01T16:18:05.225558Z","shell.execute_reply":"2025-05-01T16:18:05.319662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to display detection results with highlighted parts\ndef display_samples(images, yolo_model):\n    for i in range(50):\n        img = images[i]\n        result = yolo_model.predict(img)[0]  # Assuming batch size of 1, take the first result\n\n        plt.figure(figsize=(4, 4))\n        plt.imshow(img)\n        ax = plt.gca()\n\n        for detection in result.boxes:\n            x1, y1, x2, y2 = detection.xyxy[0].cpu().numpy()\n            conf = detection.conf[0].cpu().numpy()\n            cls = detection.cls[0].cpu().numpy()\n            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='r', facecolor='none')\n            ax.add_patch(rect)\n            plt.text(x1, y1, f\"{classes[int(cls)]} {conf:.2f}\", color='white', fontsize=12, backgroundcolor='red')\n\n        plt.title(f'YOLOv8 Detection')\n        plt.show()\n\ndisplay_samples(val_images, yolo_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:20:30.941776Z","iopub.execute_input":"2025-05-01T16:20:30.942102Z","iopub.status.idle":"2025-05-01T16:20:40.545789Z","shell.execute_reply.started":"2025-05-01T16:20:30.942077Z","shell.execute_reply":"2025-05-01T16:20:40.544840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(os.listdir('runs/detect/train3'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:18:24.785359Z","iopub.execute_input":"2025-05-01T16:18:24.785568Z","iopub.status.idle":"2025-05-01T16:18:24.790054Z","shell.execute_reply.started":"2025-05-01T16:18:24.785549Z","shell.execute_reply":"2025-05-01T16:18:24.789088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ncsv_path = 'runs/detect/train3/results.csv'  \ndf = pd.read_csv(csv_path)\n\nprint(df.columns)\nprint(df.head())\nprint(df.tail())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:18:29.266073Z","iopub.execute_input":"2025-05-01T16:18:29.266402Z","iopub.status.idle":"2025-05-01T16:18:29.284040Z","shell.execute_reply.started":"2025-05-01T16:18:29.266374Z","shell.execute_reply":"2025-05-01T16:18:29.283115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = df.index\n\nplt.figure(figsize=(10,5))\nplt.plot(epochs, df['train/box_loss'], label='Box Loss')\nplt.plot(epochs, df['train/cls_loss'], label='Class Loss')\nplt.plot(epochs, df['train/dfl_loss'], label='DFL Loss')\nplt.plot(epochs, df['val/box_loss'], label='Val Box Loss', linestyle='--')\nplt.plot(epochs, df['val/cls_loss'], label='Val Class Loss', linestyle='--')\nplt.plot(epochs, df['val/dfl_loss'], label='Val DFL Loss', linestyle='--')\nplt.title(\"Training and Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:18:38.431453Z","iopub.execute_input":"2025-05-01T16:18:38.431842Z","iopub.status.idle":"2025-05-01T16:18:38.657380Z","shell.execute_reply.started":"2025-05-01T16:18:38.431810Z","shell.execute_reply":"2025-05-01T16:18:38.656547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.plot(epochs, df['metrics/precision(B)'], label='Precision')\nplt.plot(epochs, df['metrics/recall(B)'], label='Recall')\nplt.plot(epochs, df['metrics/mAP50(B)'], label='mAP@0.5')\nplt.plot(epochs, df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\nplt.title(\"Performance Metrics\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:18:51.206396Z","iopub.execute_input":"2025-05-01T16:18:51.206753Z","iopub.status.idle":"2025-05-01T16:18:51.441558Z","shell.execute_reply.started":"2025-05-01T16:18:51.206725Z","shell.execute_reply":"2025-05-01T16:18:51.440736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load and show confusion matrix image\nimg = Image.open('runs/detect/train3/confusion_matrix.png')\nplt.figure(figsize=(12,8))\nplt.imshow(img)\nplt.axis('off')\nplt.title('Confusion Matrix (Saved)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:24:12.847192Z","iopub.execute_input":"2025-05-01T16:24:12.847510Z","iopub.status.idle":"2025-05-01T16:24:13.596251Z","shell.execute_reply.started":"2025-05-01T16:24:12.847485Z","shell.execute_reply":"2025-05-01T16:24:13.595211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# List of columns to plot (all metrics columns from your list)\nmetrics_columns = [\n    \"metrics/precision(B)\",\n    \"metrics/recall(B)\",\n    \"metrics/mAP50(B)\",\n    \"metrics/mAP50-95(B)\"\n]\n\n# Create a plot for each metric\nfor column in metrics_columns:\n    # Plotting each metric\n    plt.plot(df['epoch'], df[column], label=column)  # Use 'epoch' for x-axis\n\n    # Adding title and axis labels for each plot\n    plt.title(f\"{column} over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(f\"{column} Value\")\n    plt.grid(True)\n    plt.legend()\n    \n    # Show the plot\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:19:03.796009Z","iopub.execute_input":"2025-05-01T16:19:03.796323Z","iopub.status.idle":"2025-05-01T16:19:04.525804Z","shell.execute_reply.started":"2025-05-01T16:19:03.796298Z","shell.execute_reply":"2025-05-01T16:19:04.524828Z"}},"outputs":[],"execution_count":null}]}