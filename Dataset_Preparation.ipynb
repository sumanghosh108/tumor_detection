{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcoHQK-UmJ2z",
        "outputId": "47994e19-68e8-49d1-f8c7-c822bdaf9368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt9BpRb0mnmJ",
        "outputId": "06216690-55bb-4607-a6f1-b284048f9fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.84 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.0/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from ultralytics.utils import metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24EzIzdqmrHo",
        "outputId": "327594d3-befc-4cd8-deea-6b83aa2bda98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "# from glob import glob\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Paths to dataset\n",
        "# dataset_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/images\"\n",
        "# yes_images = glob(os.path.join(dataset_path, \"yes\", \"*.png\"))\n",
        "# no_images = glob(os.path.join(dataset_path, \"no\", \"*.png\"))\n",
        "\n",
        "# print(\"Yes images:\", len(yes_images))\n",
        "# print(\"No images:\", len(no_images))\n",
        "\n",
        "# # Split into training (80%) and validation (20%)\n",
        "# train_yes, val_yes = train_test_split(yes_images, test_size=0.2, random_state=42)\n",
        "# train_no, val_no = train_test_split(no_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Output YOLO dataset paths\n",
        "# output_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/ready_dataset\"\n",
        "\n",
        "# # Create the required folder structure\n",
        "# for split in [\"train\", \"validation\"]:\n",
        "#     os.makedirs(f\"{output_path}/{split}/images\", exist_ok=True)\n",
        "#     os.makedirs(f\"{output_path}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "# # Function to auto-detect tumor (for YES class)\n",
        "# def detect_tumor(image):\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#     _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
        "#     contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "#     # If tumor detected, return bounding box\n",
        "#     if contours:\n",
        "#         x, y, w, h = cv2.boundingRect(contours[0])\n",
        "#         return x, y, w, h\n",
        "#     return None\n",
        "\n",
        "# # Function to process images and save them in YOLO format\n",
        "# def process_images(image_list, split, class_id):\n",
        "#     for img_path in tqdm(image_list, desc=f\"Processing {split} - {class_id}\"):\n",
        "#         image = cv2.imread(img_path)\n",
        "#         h, w, _ = image.shape\n",
        "\n",
        "#         # Get bounding box for tumors in 'yes' class\n",
        "#         bbox = detect_tumor(image) if class_id == 0 else None\n",
        "\n",
        "#         # Convert bbox to YOLO format\n",
        "#         if bbox:\n",
        "#             x, y, bw, bh = bbox\n",
        "#             x_center, y_center = (x + bw/2) / w, (y + bh/2) / h\n",
        "#             bw, bh = bw / w, bh / h\n",
        "#             yolo_annotation = f\"{class_id} {x_center} {y_center} {bw} {bh}\\n\"\n",
        "#         else:\n",
        "#             yolo_annotation = \"\"\n",
        "\n",
        "#         # Save image\n",
        "#         filename = os.path.basename(img_path)\n",
        "#         cv2.imwrite(f\"{output_path}/{split}/images/{filename}\", image)\n",
        "\n",
        "#         # Save label if tumor is detected\n",
        "#         if yolo_annotation:\n",
        "#             label_path = f\"{output_path}/{split}/labels/{filename.replace('.png', '.txt')}\"\n",
        "#             with open(label_path, \"w\") as f:\n",
        "#                 f.write(yolo_annotation)\n",
        "\n",
        "# # Process both training and validation sets\n",
        "# process_images(train_yes, \"train\", 0)  # Yes Tumor -> Class 0\n",
        "# process_images(val_yes, \"validation\", 0)\n",
        "\n",
        "# process_images(train_no, \"train\", 1)  # No Tumor -> Class 1\n",
        "# process_images(val_no, \"validation\", 1)\n",
        "\n",
        "# print(\"Dataset preparation completed successfully!\")"
      ],
      "metadata": {
        "id": "Q6D8lhhkmrfK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from glob import glob\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # Define dataset paths\n",
        "# dataset_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/images\"  # Change this to your dataset location\n",
        "# output_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/ready_dataset\"  # Change this to where you want YOLO dataset\n",
        "\n",
        "# # Define class IDs\n",
        "# class_map = {\"yes\": 0, \"no\": 1}\n",
        "\n",
        "# # Create YOLOv8 formatted directories\n",
        "# for split in [\"Train\", \"Val\"]:\n",
        "#     for cls in class_map.keys():\n",
        "#         os.makedirs(os.path.join(output_path, split, cls, \"images\"), exist_ok=True)\n",
        "#         os.makedirs(os.path.join(output_path, split, cls, \"labels\"), exist_ok=True)\n",
        "\n",
        "# # Function to detect tumor (bounding box) in 'Yes' class\n",
        "# def detect_tumor(image):\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#     _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
        "#     contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "#     # If tumor detected, return bounding box\n",
        "#     if contours:\n",
        "#         x, y, w, h = cv2.boundingRect(contours[0])\n",
        "#         return x, y, w, h\n",
        "#     return None\n",
        "\n",
        "# # Function to process images and generate YOLO labels\n",
        "# def process_images(class_name, split):\n",
        "#     image_paths = glob(os.path.join(dataset_path, class_name, \"*.png\"))  # Change extension if needed\n",
        "\n",
        "#     for img_path in tqdm(image_paths, desc=f\"Processing {split}/{class_name}\"):\n",
        "#         image = cv2.imread(img_path)\n",
        "#         h, w, _ = image.shape\n",
        "#         filename = os.path.basename(img_path)\n",
        "\n",
        "#         # Bounding box for tumors in 'Yes' class\n",
        "#         if class_name == \"yes\":\n",
        "#             bbox = detect_tumor(image)\n",
        "#         else:\n",
        "#             bbox = None\n",
        "\n",
        "#         # Convert bbox to YOLO format\n",
        "#         if bbox:\n",
        "#             x, y, bw, bh = bbox\n",
        "#             x_center, y_center = (x + bw / 2) / w, (y + bh / 2) / h\n",
        "#             bw, bh = bw / w, bh / h\n",
        "#             yolo_annotation = f\"{class_map[class_name]} {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "#         else:\n",
        "#             yolo_annotation = f\"{class_map[class_name]} 0.5 0.5 1.0 1.0\\n\"  # Full image for 'No' class\n",
        "\n",
        "#         # Save image & label\n",
        "#         split_dir = os.path.join(output_path, split, class_name)\n",
        "#         cv2.imwrite(os.path.join(split_dir, \"images\", filename), image)\n",
        "\n",
        "#         label_path = os.path.join(split_dir, \"labels\", filename.replace(\".png\", \".txt\"))\n",
        "#         with open(label_path, \"w\") as f:\n",
        "#             f.write(yolo_annotation)\n",
        "\n",
        "# # Process Train & Validation sets\n",
        "# for split in [\"Train\", \"Val\"]:\n",
        "#     for cls in class_map.keys():\n",
        "#         process_images(cls, split)\n",
        "\n",
        "# print(\"âœ… Labels generated in YOLOv8 format!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Jyh6FfvevSJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define dataset paths\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/images\"\n",
        "output_path = \"/content/drive/MyDrive/Colab Notebooks/Brain_Tumor/ready_dataset\"\n",
        "\n",
        "# Define class IDs\n",
        "class_map = {\"yes\": 0, \"no\": 1}\n",
        "\n",
        "# Create YOLOv8 formatted directories\n",
        "for split in [\"Train\", \"Val\"]:\n",
        "    for cls in class_map.keys():\n",
        "        os.makedirs(os.path.join(output_path, split, cls, \"images\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, split, cls, \"labels\"), exist_ok=True)\n",
        "\n",
        "# Function to detect tumor (bounding box) in 'Yes' class\n",
        "def detect_tumor(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # If tumor detected, return bounding box\n",
        "    if contours:\n",
        "        x, y, w, h = cv2.boundingRect(contours[0])\n",
        "        return x, y, w, h\n",
        "    return None\n",
        "\n",
        "# Get image paths\n",
        "yes_images = glob(os.path.join(dataset_path, \"yes\", \"*.png\"))\n",
        "no_images = glob(os.path.join(dataset_path, \"no\", \"*.png\"))\n",
        "\n",
        "# Split into Train (80%) & Validation (20%)\n",
        "yes_train, yes_val = train_test_split(yes_images, test_size=0.2, random_state=42)\n",
        "no_train, no_val = train_test_split(no_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dictionary to store splits\n",
        "data_splits = {\n",
        "    \"Train\": {\"yes\": yes_train, \"no\": no_train},\n",
        "    \"Val\": {\"yes\": yes_val, \"no\": no_val}\n",
        "}\n",
        "\n",
        "# Function to process images and generate YOLO labels\n",
        "def process_images(class_name, split, images):\n",
        "    for img_path in tqdm(images, desc=f\"Processing {split}/{class_name}\"):\n",
        "        image = cv2.imread(img_path)\n",
        "        h, w, _ = image.shape\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # Bounding box for tumors in 'Yes' class\n",
        "        if class_name == \"yes\":\n",
        "            bbox = detect_tumor(image)\n",
        "        else:\n",
        "            bbox = None\n",
        "\n",
        "        # Convert bbox to YOLO format\n",
        "        if bbox:\n",
        "            x, y, bw, bh = bbox\n",
        "            x_center, y_center = (x + bw / 2) / w, (y + bh / 2) / h\n",
        "            bw, bh = bw / w, bh / h\n",
        "            yolo_annotation = f\"{class_map[class_name]} {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "        else:\n",
        "            yolo_annotation = f\"{class_map[class_name]} 0.5 0.5 1.0 1.0\\n\"  # Full image for 'No' class\n",
        "\n",
        "        # Save image & label\n",
        "        split_dir = os.path.join(output_path, split, class_name)\n",
        "        shutil.copy(img_path, os.path.join(split_dir, \"images\", filename))\n",
        "\n",
        "        label_path = os.path.join(split_dir, \"labels\", filename.replace(\".png\", \".txt\"))\n",
        "        with open(label_path, \"w\") as f:\n",
        "            f.write(yolo_annotation)\n",
        "\n",
        "# Process Train & Validation sets\n",
        "for split, classes in data_splits.items():\n",
        "    for cls, images in classes.items():\n",
        "        process_images(cls, split, images)\n",
        "\n",
        "print(\"âœ… Dataset split & YOLO labels generated successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNE9376e0Wfo",
        "outputId": "f6b14a91-4156-46a7-f945-e9525d9bdfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Train/yes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6418/6418 [07:51<00:00, 13.60it/s]\n",
            "Processing Train/no: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7636/7636 [1:49:46<00:00,  1.16it/s]\n",
            "Processing Val/yes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1605/1605 [00:38<00:00, 41.22it/s]\n",
            "Processing Val/no: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1910/1910 [26:57<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset split & YOLO labels generated successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}