{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1938303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb5f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001\n",
    "RANDOM_STATE = 32\n",
    "DATA_DIR = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33110530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save models if it does not exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Create a folder to save the plots if it does not exist\n",
    "os.makedirs(\"plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610bdac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13563 images belonging to 2 classes.\n",
      "Found 5811 images belonging to 2 classes.\n",
      "Found 19374 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# Training data (70%)\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Validation data (20%)\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Testing data (10%)\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ee280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Models\n",
    "def create_cnn():\n",
    "    model = Sequential([\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_vgg16():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_vgg19():\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_resnet101():\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile function\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b742df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN model...\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 503s 5s/step - loss: 0.5720 - accuracy: 0.6900 - val_loss: 0.6041 - val_accuracy: 0.6825\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 404s 4s/step - loss: 0.4820 - accuracy: 0.7697 - val_loss: 0.5232 - val_accuracy: 0.7443\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 439s 4s/step - loss: 0.4432 - accuracy: 0.7943 - val_loss: 0.5259 - val_accuracy: 0.7503\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 413s 4s/step - loss: 0.4159 - accuracy: 0.8099 - val_loss: 0.4978 - val_accuracy: 0.7551\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 465s 4s/step - loss: 0.3930 - accuracy: 0.8270 - val_loss: 0.4848 - val_accuracy: 0.7689\n",
      "CNN - Test Loss: 0.3981, Test Accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prachi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model saved successfully at: models/cnn_model.h5\n",
      "Training VGG16 model...\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 6968s 66s/step - loss: 0.4350 - accuracy: 0.8009 - val_loss: 0.3491 - val_accuracy: 0.8551\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 9443s 90s/step - loss: 0.2817 - accuracy: 0.8912 - val_loss: 0.2796 - val_accuracy: 0.8883\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 5766s 55s/step - loss: 0.2278 - accuracy: 0.9168 - val_loss: 0.2462 - val_accuracy: 0.9026\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 5631s 53s/step - loss: 0.1972 - accuracy: 0.9290 - val_loss: 0.2225 - val_accuracy: 0.9124\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 5573s 53s/step - loss: 0.1750 - accuracy: 0.9382 - val_loss: 0.2081 - val_accuracy: 0.9193\n",
      "VGG16 - Test Loss: 0.1643, Test Accuracy: 0.9422\n",
      "VGG16 model saved successfully at: models/vgg16_model.h5\n",
      "Training VGG19 model...\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 7083s 67s/step - loss: 0.4579 - accuracy: 0.7850 - val_loss: 0.3744 - val_accuracy: 0.8431\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 12756s 121s/step - loss: 0.3075 - accuracy: 0.8799 - val_loss: 0.3075 - val_accuracy: 0.8770\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 7311s 69s/step - loss: 0.2567 - accuracy: 0.9036 - val_loss: 0.2732 - val_accuracy: 0.8918\n",
      "Epoch 4/5\n",
      " 82/106 [======================>.......] - ETA: 24:01 - loss: 0.2274 - accuracy: 0.9172"
     ]
    }
   ],
   "source": [
    "# 3. Model Training and Evaluation\n",
    "models = {\n",
    "    \"CNN\": create_cnn(),\n",
    "    \"VGG16\": create_vgg16(),\n",
    "    \"VGG19\": create_vgg19(),\n",
    "    \"ResNet101\": create_resnet101()\n",
    "}\n",
    "\n",
    "history_dict = {}\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    model = compile_model(model)\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1\n",
    "    )\n",
    "    # Store history\n",
    "    history_dict[model_name] = history\n",
    "    # Evaluate model\n",
    "    loss, accuracy = model.evaluate(test_gen, verbose=0)\n",
    "    results[model_name] = (loss, accuracy)\n",
    "    print(f\"{model_name} - Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_filename = f\"models/{model_name.lower()}_model.h5\"\n",
    "    model.save(model_filename)\n",
    "    print(f\"{model_name} model saved successfully at: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a355d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot Loss and Accuracy Graphs\n",
    "def plot_metrics(history_dict):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, history in history_dict.items():\n",
    "        plt.plot(history.history['accuracy'], label=f'{model_name} Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{model_name} Val Accuracy')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, history in history_dict.items():\n",
    "        plt.plot(history.history['loss'], label=f'{model_name} Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label=f'{model_name} Val Loss')\n",
    "    plt.title('Model Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Plot metrics\n",
    "plot_metrics(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c360343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to save the plots if it does not exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Function to plot individual accuracy and loss graphs for each model\n",
    "def plot_individual_metrics(history_dict):\n",
    "    for model_name, history in history_dict.items():\n",
    "        # Plot Accuracy\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "        plt.title(f'{model_name} Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(f\"plots/{model_name.lower()}_accuracy.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "        plt.title(f'{model_name} Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(f\"plots/{model_name.lower()}_loss.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "# Plot individual metrics for each model\n",
    "plot_individual_metrics(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Confusion Matrices and Performance Metrics\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nGenerating Confusion Matrix for {model_name}...\")\n",
    "    y_pred = model.predict(test_gen)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['No Tumor', 'Tumor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2e297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
